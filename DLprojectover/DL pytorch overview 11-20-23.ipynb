{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6a15d4f",
   "metadata": {},
   "source": [
    "# Rough overview:\n",
    "\n",
    "\n",
    "## Sketch the model you are trying to create\n",
    "\n",
    "## Remember just like any programming problem break it into smaller subparts\n",
    "\n",
    "\n",
    "\n",
    "dataset -> model -> training and backprob -> eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b08c368",
   "metadata": {},
   "source": [
    "# Datasets\n",
    "\n",
    "**Data loader. Combines a dataset and a sampler, and provides an iterable over\n",
    "the given dataset** \n",
    "\n",
    "from torch.utils.data import DataLoader \n",
    "\n",
    "\n",
    "### What to do for a custom dataset\n",
    "https://towardsdatascience.com/beginners-guide-to-loading-image-data-with-pytorch-289c60b7afec\n",
    "\n",
    "https://stanford.edu/~shervine/blog/pytorch-how-to-generate-data-parallel\n",
    "\n",
    "## What you need to do\n",
    "\n",
    "Remember to normalize the inputs when working with images so pixel intensity doesn't mess up images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aa2de4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13f312d6",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "## modules and imports\n",
    "\n",
    "nn.Module <- subclass for all models\n",
    "\n",
    "from torch.nn.modules.activation import X: for activations.\n",
    "\n",
    "torch.nn.Dropout(p=0.5, inplace=False), randomly zeros out some elements of the input tensor, using probably p from the Bernoulli. generally is put in fully connect after activation function. mainly for overfitting, do not use if underfitting. if droppout is too strong can use it before the final layer.\n",
    "\n",
    "---------------\n",
    "\n",
    "## What you need to do.\n",
    "\n",
    "Every model will need an init with a super() and a forward() method, usually set up layers or blocks in the init and in the forward method give the path the data passes through, returning the outputs. e.g logits in a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ccc1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6a0fe0a",
   "metadata": {},
   "source": [
    "# Training loop\n",
    "\n",
    "## modules and imports\n",
    "\n",
    "all optimizers take in model params first and a learning rate second\n",
    "\n",
    "optim.SGD(net.parameters(),lr,momentum=x)\n",
    "\n",
    "import torch.optim as optim: for optimizers\n",
    "\n",
    "you have to assign the inputs to the inputs after you send them to a device inputs = inputs.to(device)\n",
    "\n",
    "check to make sure tensor is on cuda with .is_cuda\n",
    "\n",
    "\n",
    "\n",
    "basic training loops seems to be dataloader -> preds -> error -> backprob optimizer \n",
    "\n",
    "## What you in general need to do\n",
    "\n",
    "#### range of epochs for outer loop\n",
    "\n",
    "-set running loss.\n",
    "\n",
    "#### have an inner loop enumerating the dataloader and a variable i, i just keeping track of mini-batches for statistics\n",
    "\n",
    "-get batch and labels from dataloader\n",
    "\n",
    "-zero out the optimizer parameters for each minibatch\n",
    "\n",
    "-do forward pass by calling the model with the batch (this is handled by the forward method defined in the model)\n",
    "\n",
    "-get the loss by calling your loss function, in pytorch its loss_fn(preds,labels) (usually)\n",
    "\n",
    "-then loss.backward() for reverse mode autodiff()?\n",
    "\n",
    "-then optimizer.step() for updating the model parameters w.r.t the loss fn\n",
    "\n",
    "-adding the loss to the running loss \n",
    "\n",
    "-usually you will want some statistics to be printed every 2000 or so mini-batches. You can have it just print or have it be saved to tensorboard.\n",
    "\n",
    "-if you are using running loss to describe statistics during a batch of mini-batches remember to zero it after printing the statistics\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7727aeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0eac3cba",
   "metadata": {},
   "source": [
    "# Evalutation\n",
    "\n",
    "\n",
    "\n",
    "## What you need to do:\n",
    "\n",
    "Use the context manager torch.no_grad() to disable gradient calculation for inference (can also be used as a decorator).\n",
    "\n",
    "Then go through batches from the test loader and caluclate how many you got right or wrong.\n",
    "\n",
    "### Classifcation\n",
    "\n",
    "if doing multi-class classification use torch.max() to get the predicted class indicies, be careful because it returns a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92416850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3e67f76",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "mainly just use stack overflow, but maybe check these if needed.\n",
    "\n",
    "### Forum\n",
    "https://discuss.pytorch.org/\n",
    "\n",
    "### Slack\n",
    "\n",
    "https://pytorch.slack.com/?redir=%2Fmessages%2Fbeginner%2F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cea595f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f3b705c",
   "metadata": {},
   "source": [
    "## To read\n",
    "\n",
    "### CUDA Stuff\n",
    "https://pytorch.org/docs/stable/notes/cuda.html#cuda-memory-pinning\n",
    "\n",
    "\n",
    "### Python multithreading\n",
    "https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing\n",
    "\n",
    "### Data parallelism\n",
    "https://pytorch.org/tutorials/beginner/blitz/data_parallel_tutorial.html\n",
    "\n",
    "\n",
    "### Custom datasets\n",
    "https://pytorch.org/tutorials/beginner/basics/data_tutorial.html?highlight=datasets\n",
    "\n",
    "https://pytorch.org/docs/stable/data.html#module-torch.utils.data\n",
    "\n",
    "### NN package stuff\n",
    "https://pytorch.org/tutorials/beginner/former_torchies/nnft_tutorial.html?highlight=nn%20module\n",
    "\n",
    "### Autograd in Torch\n",
    "https://pytorch.org/docs/stable/notes/autograd.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df5588e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71f06cbe",
   "metadata": {},
   "source": [
    "# Packages\n",
    "\n",
    "\n",
    "### Probability distriubtions\n",
    "https://pytorch.org/docs/stable/distributions.html#module-torch.distributions.transforms\n",
    "\n",
    "\n",
    "### Tensorboard methods\n",
    "https://pytorch.org/docs/stable/tensorboard.html#torch.utils.tensorboard.writer.SummaryWriter\n",
    "\n",
    "### Optimizers (SGD,AdaGrad,etc)\n",
    "https://pytorch.org/docs/stable/optim.html\n",
    "\n",
    "### NN (containers, layers)\n",
    "https://pytorch.org/docs/stable/nn.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
